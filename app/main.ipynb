{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook acting as a User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShopAssist AI: Intelligent Laptop Shopping Assistant\n",
    "\n",
    "**Project Overview**\n",
    "- ShopAssist AI is an innovative chatbot designed to transform the online laptop shopping experience. By leveraging the power of Large Language Models (LLMs) and rule-based functions, this intelligent assistant provides accurate and personalized laptop recommendations based on user requirements. ShopAssist AI aims to simplify the overwhelming nature of online shopping by guiding users in finding the perfect laptop tailored to their needs.\n",
    "\n",
    "**Problem Statement**\n",
    "- In the digital shopping era, the abundance of options can make it difficult for consumers to make informed decisions. This project addresses the challenge of:\n",
    "\n",
    "    - Interacting with users to gather their requirements.\n",
    "    - Parsing a dataset of laptops to extract relevant information.\n",
    "    - Recommending the most suitable laptops based on user preferences.\n",
    "    - \n",
    "**Key Objectives**:\n",
    "- Engage users: Provide natural and interactive conversations to understand user requirements.\n",
    "- Extract insights: Use LLMs and rule-based reasoning to map user preferences to the dataset.\n",
    "- Recommend effectively: Suggest the top three laptops matching user needs and answer follow-up queries.\n",
    "\n",
    "**Solution Approach**\n",
    "1. Conversation and Information Gathering\n",
    "- The chatbot initiates a natural conversation to collect user requirements, such as budget, specifications, and usage needs.\n",
    "Moderation checks ensure the conversation is safe and free of sensitive content.\n",
    "2. Information Extraction\n",
    "- The system analyzes user requirements using natural language understanding (NLU).\n",
    "It filters laptops from the dataset based on extracted features and calculates compatibility scores.\n",
    "3. Personalized Recommendations\n",
    "- Presents a maximum of three laptops, ranked by relevance to user requirements.\n",
    "In cases where no laptops meet the threshold, the system connects the user with a human expert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Intent Clarity and Confirmation\n",
    "This stage involves initiating and managing the conversation between the user and the AI system.\n",
    "\n",
    "Key Functions:\n",
    "- initialize_conversation(): Starts the conversation with the user.\n",
    "- get_chat_completions(): Continuously processes user inputs and generates LLM responses.\n",
    "- moderation_check(): Flags and halts conversations containing unsafe or sensitive content.\n",
    "\n",
    "### Stage 2: Product Mapping and Information Extraction\n",
    "This stage filters laptops based on user requirements and identifies the top recommendations.\n",
    "\n",
    "Key Functions:\n",
    "- product_map_layer(): Extracts and maps key features (e.g., GPU intensity, display quality) from the dataset.\n",
    "- compare_laptops_with_user(): Matches user requirements against the laptop features to calculate scores.\n",
    "- recommendation_validation(): Validates the recommendations to ensure they meet quality thresholds.\n",
    "\n",
    "### Stage 3: Product Recommendation\n",
    "This stage delivers recommendations and engages in further conversation.\n",
    "\n",
    "Key Functions:\n",
    "- initialize_conv_reco(): Generates a structured conversation with summarized laptop recommendations.\n",
    "- get_chat_completions(): Facilitates follow-up queries and detailed discussions about the recommended laptops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![complete_flow.jpg](/Users/imkushwaha/IIITB-AIML/ShopAssistApp/app/img/CompleteFlow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from shopassist.services.stage1 import (initialize_conversation, \n",
    "                                        get_chat_completions, \n",
    "                                        moderation_check, \n",
    "                                        intent_confirmation_layer,\n",
    "                                        dictionary_present)\n",
    "from shopassist.services.stage3 import initialize_conv_reco\n",
    "from shopassist.services.stage2 import (compare_laptops_with_user, \n",
    "                                        recommendation_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY_PATH = os.path.join(\"shopassist\", \"config\", \"OPENAI_API_KEY.txt\")\n",
    "openai.api_key = open(OPENAI_API_KEY_PATH, \"r\").read().strip()\n",
    "os.environ['OPENAI_API_KEY'] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_mgmt_system():\n",
    "    conversation = initialize_conversation()\n",
    "\n",
    "    introduction = get_chat_completions(conversation)\n",
    "\n",
    "    display(introduction + '\\n')\n",
    "\n",
    "    top_3_laptops = None\n",
    "\n",
    "    user_input = ''\n",
    "\n",
    "    while(user_input != \"exit\"):\n",
    "\n",
    "        user_input = input(\"\")\n",
    "\n",
    "        moderation = moderation_check(user_input)\n",
    "        if moderation == 'Flagged':\n",
    "            display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "            break\n",
    "\n",
    "        if top_3_laptops is None:\n",
    "\n",
    "            conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "            response_assistant = get_chat_completions(conversation)\n",
    "            moderation = moderation_check(response_assistant)\n",
    "            if moderation == 'Flagged':\n",
    "                display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                break\n",
    "\n",
    "\n",
    "            confirmation = intent_confirmation_layer(response_assistant)\n",
    "\n",
    "            print(\"Intent Confirmation Yes/No:\",confirmation.get('result'))\n",
    "\n",
    "            if \"No\" in confirmation.get('result'):\n",
    "                conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
    "                print(\"\\n\" + str(response_assistant) + \"\\n\")\n",
    "\n",
    "            else:\n",
    "                print(\"\\n\" + str(response_assistant) + \"\\n\")\n",
    "                print('\\n' + \"Variables extracted!\" + '\\n')\n",
    "\n",
    "                response = dictionary_present(response_assistant)\n",
    "\n",
    "                print(\"Thank you for providing all the information. Kindly wait, while I fetch the products: \\n\")\n",
    "                top_3_laptops = compare_laptops_with_user(response)\n",
    "\n",
    "                print(\"top 3 laptops are\", top_3_laptops)\n",
    "\n",
    "                validated_reco = recommendation_validation(top_3_laptops)\n",
    "\n",
    "                conversation_reco = initialize_conv_reco(validated_reco)\n",
    "\n",
    "                conversation_reco.append({\"role\": \"user\", \"content\": \"This is my user profile\" + str(response)})\n",
    "\n",
    "                recommendation = get_chat_completions(conversation_reco)\n",
    "\n",
    "                moderation = moderation_check(recommendation)\n",
    "                if moderation == 'Flagged':\n",
    "                    display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                    break\n",
    "\n",
    "                conversation_reco.append({\"role\": \"assistant\", \"content\": str(recommendation)})\n",
    "\n",
    "                print(str(recommendation) + '\\n')\n",
    "        else:\n",
    "            conversation_reco.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "            response_asst_reco = get_chat_completions(conversation_reco)\n",
    "\n",
    "            moderation = moderation_check(response_asst_reco)\n",
    "            if moderation == 'Flagged':\n",
    "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
    "                break\n",
    "\n",
    "            print('\\n' + response_asst_reco + '\\n')\n",
    "            conversation.append({\"role\": \"assistant\", \"content\": response_asst_reco})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
